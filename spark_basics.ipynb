{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8815f59-702f-4694-81de-7f4f7956311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rid\n"
     ]
    }
   ],
   "source": [
    "print('rid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2c9da3-d8c2-4a45-b56a-a9fd8542e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in ./.local/lib/python3.10/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6153b4c1-eca4-4bf0-8daa-28c5754e2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0792659d-3bfa-48da-b05b-855277fe48d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simran</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jyoti</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ridhi</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tania</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Age\n",
       "0  Simran   23\n",
       "1   jyoti   23\n",
       "2   ridhi   24\n",
       "3   tania   26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/home/rythm/Documents/test_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294dfb5f-cf35-40d9-a1be-e3854b49fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2367193b-831e-47f2-903c-d9ed25990568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/27 10:29:25 WARN Utils: Your hostname, rythm-VivoBook-ASUSLaptop-X421FL-S433FL resolves to a loopback address: 127.0.1.1; using 172.20.10.3 instead (on interface wlo1)\n",
      "25/04/27 10:29:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/27 10:29:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d05f449-b8e3-4038-8917-eb0bc1f2efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x79a3c3a96110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5edd5e2-5d23-4d16-aa22-1b1573043382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('/home/rythm/Documents/test_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4cfe03e-ab22-4e80-8551-da84425ca440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "477402fb-72c7-4215-9462-965d1227c402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('/home/rythm/Documents/test_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e20ae33-2b72-4f17-a829-e25d3b99ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Simran| 23|\n",
      "| jyoti| 23|\n",
      "| ridhi| 24|\n",
      "| tania| 26|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('/home/rythm/Documents/test_data1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1121d4-d969-4971-8a0c-3f70cb2afe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('/home/rythm/Documents/test_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e218b0-8c66-4258-a06d-f354e0a5c5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc92f310-61e0-4bc9-a936-6c11afd8eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Simran', Age='23'),\n",
       " Row(Name='jyoti', Age='23'),\n",
       " Row(Name='ridhi', Age='24'),\n",
       " Row(Name='tania', Age='26')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99d6f473-3fe1-4967-9c96-f55de09883d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54737a51-6ba9-435a-96b7-5f991fd83994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('/home/rythm/Documents/test_data1.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee76f37-ef12-4d39-8575-25e8a6e345f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb3eb7ea-9ce6-4241-95f0-4af7ef462ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  Name|\n",
      "+------+\n",
      "|Simran|\n",
      "| jyoti|\n",
      "| ridhi|\n",
      "| tania|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a301dc65-0890-4b20-91ca-0da6263b170f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3586ef9-1330-4974-a609-c1c3ee66befa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|age|\n",
      "+------+---+\n",
      "|Simran| 23|\n",
      "| jyoti| 23|\n",
      "| ridhi| 24|\n",
      "| tania| 26|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15cfb8c1-fbb7-410e-876b-26175e81583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06f357de-c65a-42c7-8957-90e56986e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+\n",
      "|summary|  Name|               Age|\n",
      "+-------+------+------------------+\n",
      "|  count|     4|                 4|\n",
      "|   mean|  NULL|              24.0|\n",
      "| stddev|  NULL|1.4142135623730956|\n",
      "|    min|Simran|                23|\n",
      "|    max| tania|                26|\n",
      "+-------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4088090-3949-4533-be84-f958a61d25b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+\n",
      "|  Name|Age|Age after 2 years|\n",
      "+------+---+-----------------+\n",
      "|Simran| 23|               25|\n",
      "| jyoti| 23|               25|\n",
      "| ridhi| 24|               26|\n",
      "| tania| 26|               28|\n",
      "+------+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# adding column in dataframe\n",
    "\n",
    "df_pyspark.withColumn('Age after 2 years',df_pyspark['Age']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2381e2-f7d3-470c-a615-5a5e7e847b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.withColumn('Age after 2 years',df_pyspark['Age']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b0e5916-680b-44e7-aaf0-c7d90a792063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+\n",
      "|  Name|Age|Age after 2 years|\n",
      "+------+---+-----------------+\n",
      "|Simran| 23|               25|\n",
      "| jyoti| 23|               25|\n",
      "| ridhi| 24|               26|\n",
      "| tania| 26|               28|\n",
      "+------+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54bf2c78-116d-4596-b663-94ccc417e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------------+\n",
      "|New Name|Age|Age after 2 years|\n",
      "+--------+---+-----------------+\n",
      "|  Simran| 23|               25|\n",
      "|   jyoti| 23|               25|\n",
      "|   ridhi| 24|               26|\n",
      "|   tania| 26|               28|\n",
      "+--------+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rename the column\n",
    "df_pyspark.withColumnRenamed('Name','New Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c789a74-ae0f-4319-9696-ddaf31d8508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('Salary',df_pyspark['Age']*10000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a57b509-b880-4746-916d-c3826c3715fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.withColumn('Salary',df_pyspark['Age']*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca2c5c6-f6bc-4abe-918b-ccb46aebba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbbe521f-7349-475d-b7c6-0a4ca0614ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+------+\n",
      "|Age|Age after 2 years|Salary|\n",
      "+---+-----------------+------+\n",
      "| 23|               25|230000|\n",
      "| 23|               25|230000|\n",
      "| 24|               26|240000|\n",
      "| 26|               28|260000|\n",
      "+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the column\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acfaa01a-570e-4816-a199-a5029e152935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# removing the null values\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d5da508-bfb8-4997-b33d-6d9346ca9f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any',thresh=2).show() # stleast having 2 non null values in row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0af01131-de29-4360-96d9-c1dc08a868ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fill the values in the columns\n",
    "df_pyspark.na.fill('Missing Values',['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b53e8cb-1408-4985-9cc4-f485ade883b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49877f38-91bf-4a14-9e4d-9bd61403326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=Imputer(\n",
    "    inputCols=['Age','Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age','Salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eef8893-3722-4ffa-9ab7-f581b7533c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+-----------+--------------+\n",
      "|  Name|Age|Age after 2 years|Salary|Age_imputed|Salary_imputed|\n",
      "+------+---+-----------------+------+-----------+--------------+\n",
      "|Simran| 23|               25|230000|         23|        230000|\n",
      "| jyoti| 23|               25|230000|         23|        230000|\n",
      "| ridhi| 24|               26|240000|         24|        240000|\n",
      "| tania| 26|               28|260000|         26|        260000|\n",
      "+------+---+-----------------+------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f385e6be-b73f-404d-97d8-8f401ecab1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter operations\n",
    "df_pyspark.filter('Salary>=25000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b1f81b5-444c-4ad2-b58f-8f29e33a0ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|age|\n",
      "+------+---+\n",
      "|Simran| 23|\n",
      "| jyoti| 23|\n",
      "| ridhi| 24|\n",
      "| tania| 26|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Salary>=25000\").select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f52faa26-5c35-4e80-ad14-9a064e26f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Salary']<=26000) & (df_pyspark['Salary']>=150000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6adf3246-9d22-47df-b1f0-cf3751dd6873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------------+-----------+\n",
      "|Age|sum(Age)|sum(Age after 2 years)|sum(Salary)|\n",
      "+---+--------+----------------------+-----------+\n",
      "| 26|      26|                    28|     260000|\n",
      "| 23|      46|                    50|     460000|\n",
      "| 24|      24|                    26|     240000|\n",
      "+---+--------+----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Age').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae6e115a-5806-44a8-8824-b4a97d8a4177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------------+-----------+\n",
      "|Age|avg(Age)|avg(Age after 2 years)|avg(Salary)|\n",
      "+---+--------+----------------------+-----------+\n",
      "| 26|    26.0|                  28.0|   260000.0|\n",
      "| 23|    23.0|                  25.0|   230000.0|\n",
      "| 24|    24.0|                  26.0|   240000.0|\n",
      "+---+--------+----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Age').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b26d1bbe-d716-42f4-933c-3983631118c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|Age|count|\n",
      "+---+-----+\n",
      "| 26|    1|\n",
      "| 23|    2|\n",
      "| 24|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby('Age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d32d66bf-52e4-47d5-a777-c36fea860fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+\n",
      "|  Name|Age|Age after 2 years|Salary|\n",
      "+------+---+-----------------+------+\n",
      "|Simran| 23|               25|230000|\n",
      "| jyoti| 23|               25|230000|\n",
      "| ridhi| 24|               26|240000|\n",
      "| tania| 26|               28|260000|\n",
      "+------+---+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf6667c8-d8d0-482e-abab-af7a295c9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92899bad-046f-4118-9068-3ed265b79263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn(\n",
    "    'Experience',\n",
    "    F.when(df_pyspark['Age'] < 24, 1).otherwise(2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b880b33e-ba57-4146-bd94-a170c95707fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+----------+\n",
      "|  Name|Age|Age after 2 years|Salary|Experience|\n",
      "+------+---+-----------------+------+----------+\n",
      "|Simran| 23|               25|230000|         1|\n",
      "| jyoti| 23|               25|230000|         1|\n",
      "| ridhi| 24|               26|240000|         2|\n",
      "| tania| 26|               28|260000|         2|\n",
      "+------+---+-----------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe7a4e4f-84e3-4888-aa27-6d3260d4c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f4bd180-ad78-4ef2-9b50-37f433e97014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+----------+\n",
      "|  Name|Age|Age after 2 years|Salary|Experience|\n",
      "+------+---+-----------------+------+----------+\n",
      "|Simran| 23|               25|230000|         1|\n",
      "| jyoti| 23|               25|230000|         1|\n",
      "| ridhi| 24|               26|240000|         2|\n",
      "| tania| 26|               28|260000|         2|\n",
      "+------+---+-----------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e995334-4bda-456c-93c4-42b27de1d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Age after 2 years: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85c74665-fbe2-4f8e-8db3-c0d668c5a80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Age after 2 years', 'Salary', 'Experience']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fa2ab6d-d240-45b5-addf-0b5cbdb1d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Age','Experience']---> new feature----> independent featiure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3b3e160-66f5-45fb-8afc-e45f250541e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3358ceb-0652-43fc-816d-b810d784149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureassembler=VectorAssembler(inputCols=['Age','Experience'],outputCol='Independent Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00fee75f-408e-49cf-b4ea-68e14af66576",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58bbe8bd-b8fb-4b8e-8d28-c6b259e2e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------------+------+----------+-------------------+\n",
      "|  Name|Age|Age after 2 years|Salary|Experience|Independent Feature|\n",
      "+------+---+-----------------+------+----------+-------------------+\n",
      "|Simran| 23|               25|230000|         1|         [23.0,1.0]|\n",
      "| jyoti| 23|               25|230000|         1|         [23.0,1.0]|\n",
      "| ridhi| 24|               26|240000|         2|         [24.0,2.0]|\n",
      "| tania| 26|               28|260000|         2|         [26.0,2.0]|\n",
      "+------+---+-----------------+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da73581d-3c79-47b9-aaf7-990a06cd0385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'Age',\n",
       " 'Age after 2 years',\n",
       " 'Salary',\n",
       " 'Experience',\n",
       " 'Independent Feature']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e1902fc-e92e-4b3a-a998-4657e9102708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only need two features rn\n",
    "finalized_data=output.select('Independent Feature','Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b093b983-46c9-40f7-89f4-8f17fa42f0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|Independent Feature|Salary|\n",
      "+-------------------+------+\n",
      "|         [23.0,1.0]|230000|\n",
      "|         [23.0,1.0]|230000|\n",
      "|         [24.0,2.0]|240000|\n",
      "|         [26.0,2.0]|260000|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c44088a9-59f1-4317-bdaa-2e7d0b63d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/27 16:45:10 WARN Instrumentation: [fae7b8c6] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Independent Feature', labelCol='Salary')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1208564-3bd5-499c-9191-95b8fef0f337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([10000.0, 0.0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4958ca1-1b91-4e66-816d-939b37603d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5272199645993122e-08"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c6fd813-3aba-4556-b8aa-5e252808cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34fe7036-4233-4141-8422-4207c1f98a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------------------+\n",
      "|Independent Feature|Salary|        prediction|\n",
      "+-------------------+------+------------------+\n",
      "|         [23.0,1.0]|230000|230000.00000000047|\n",
      "+-------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3fba7-fb37-4006-9bda-dea993727454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
